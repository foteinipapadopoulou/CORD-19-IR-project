{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "7b4e7fc144604c3ebfa5bfed57bcce4c",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Download the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "66e4d0f9d77b4cf2bdea69b027bd42a5",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5484,
    "execution_start": 1700939372961,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "!pip install -r /kaggle/input/requirements/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "baf6405aeb85472396b5b52d54d6a1d3",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Installing Java as it is needed for pyterrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "ee038bbefe064ed9972f254ce4aba10d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 947,
    "execution_start": 1700939378452,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "!apt-get install -y default-jre\n",
    "!apt-get update && \\\n",
    "    apt-get install -y openjdk-11-jdk ca-certificates-java && \\\n",
    "    apt-get clean && \\\n",
    "    update-ca-certificates -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "cell_id": "950e97eab6694ef78dc589818ae13f59",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution": {
     "iopub.execute_input": "2023-12-04T21:49:27.899026Z",
     "iopub.status.busy": "2023-12-04T21:49:27.898058Z",
     "iopub.status.idle": "2023-12-04T21:49:27.943984Z",
     "shell.execute_reply": "2023-12-04T21:49:27.942761Z",
     "shell.execute_reply.started": "2023-12-04T21:49:27.898991Z"
    },
    "execution_millis": 2558,
    "execution_start": 1700939382800,
    "source_hash": null
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyt_deepimpact'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyterrier_doc2query\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Doc2Query, QueryScorer, QueryFilter\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyterrier_dr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ElectraScorer\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyt_deepimpact\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeepImpactIndexer\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyt_deepimpact'"
     ]
    }
   ],
   "source": [
    "import pyterrier as pt\n",
    "if not pt.started():\n",
    "    pt.init()\n",
    "pt.logging(\"INFO\")\n",
    "\n",
    "from pyterrier.measures import *\n",
    "from pyterrier_doc2query import Doc2Query, QueryScorer, QueryFilter\n",
    "from pyterrier_dr import ElectraScorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_name):\n",
    "    dataset = pt.get_dataset(dataset_name)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "2b909c72bb3e47d487f437104154f606",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 9,
    "execution_start": 1700939385359,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    Iterating over docs to remove duplicate and empty docs\n",
    "    Code retrieved by : https://github.com/terrierteam/pyterrier_deepimpact/blob/main/cord19_example.py \n",
    "\"\"\"\n",
    "def text_iter(doc_iter):\n",
    "    encountered_docnos = set()\n",
    "    for doc in doc_iter:\n",
    "        # Skipping over empty docs\n",
    "        if len(doc['title'].strip()) == 0 or len(doc['abstract'].strip()) == 0:\n",
    "            continue\n",
    "        # Skipping over duplicate docs and merging fields\n",
    "        if doc['docno'] not in encountered_docnos:\n",
    "            yield {\"docno\": doc['docno'], \"text\": '{title} {abstract}'.format(**doc)}\n",
    "            encountered_docnos.add(doc['docno'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up some constants for the CORD-19 dataset for each round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_TREC_COVID_DATASET_NAME = \"irds:cord19/trec-covid\"\n",
    "ROUND_TREC_COVID_DATASET_NAME = f\"{FULL_TREC_COVID_DATASET_NAME}/round\"\n",
    "STAND_INDEX_NAME = 'standard_index_round'\n",
    "DOC2QUERY_INDEX_NAME = 'doc2query--_index_round'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexing(trec_covid_round):\n",
    "    round_dataset = load_dataset(f'{ROUND_TREC_COVID_DATASET_NAME}{trec_covid_round}')\n",
    "\n",
    "    # Creating index cord19\n",
    "    indexer = pt.IterDictIndexer(f'./{STAND_INDEX_NAME}{trec_covid_round}')\n",
    "    index_ref = indexer.index(text_iter(round_dataset.get_corpus_iter()))\n",
    "    return index_ref, round_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieval(index_ref, round_dataset):\n",
    "    # Preparing the models\n",
    "    tfidf = pt.BatchRetrieve(index_ref, wmodel=\"TF_IDF\")\n",
    "    bm25 = pt.BatchRetrieve(index_ref, wmodel=\"BM25\")\n",
    "    dir = pt.BatchRetrieve(index_ref, wmodel=\"DirichletLM\")\n",
    "\n",
    "    # Evaluation\n",
    "    exp = pt.Experiment(\n",
    "        [tfidf,bm25,dir],\n",
    "        round_dataset.get_topics(variant='title'),\n",
    "        round_dataset.get_qrels(),\n",
    "        eval_metrics=[P@20,R@20,'map',nDCG@20],\n",
    "        round = 4,\n",
    "        names=[\"TF_IDF\", \"BM25\",\"DirichletLM\"])\n",
    "    return exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard Indexing and Retrieval for each round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trec_covid_round = 1\n",
    "index_ref_1, round_dataset_1 = indexing(trec_covid_round)\n",
    "experiment_1 = retrieval(index_ref_1,round_dataset_1)\n",
    "print(experiment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trec_covid_round = 2\n",
    "index_ref_2, round_dataset_2 = indexing(trec_covid_round)\n",
    "experiment_2 = retrieval(index_ref_2,round_dataset_2)\n",
    "print(experiment_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trec_covid_round = 3\n",
    "index_ref_3, round_dataset_3 = indexing(trec_covid_round)\n",
    "experiment_3 = retrieval(index_ref_3,round_dataset_3)\n",
    "print(experiment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trec_covid_round = 4\n",
    "index_ref_4, round_dataset_4 = indexing(trec_covid_round)\n",
    "experiment_4 = retrieval(index_ref_4,round_dataset_4)\n",
    "print(experiment_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trec_covid_round = 5\n",
    "index_ref_5, round_dataset_5 = indexing(trec_covid_round)\n",
    "experiment_5 = retrieval(index_ref_5,round_dataset_5)\n",
    "print(experiment_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c12348c52fa9489da5152956d8c1f856",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Doc2Query-- indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc2query_minus_minus_indexing(trec_covid_round, doc2query, scorer):\n",
    "    round_dataset = load_dataset(f'{ROUND_TREC_COVID_DATASET_NAME}{trec_covid_round}')\n",
    "    index = pt.IterDictIndexer(f'./{DOC2QUERY_INDEX_NAME}{trec_covid_round}')\n",
    "    pipeline = doc2query >> QueryScorer(scorer) >> QueryFilter(append=True, t=3.21484375) >> index\n",
    "    \n",
    "    index_ref = pipeline.index(text_iter(round_dataset.get_corpus_iter()))\n",
    "    return index_ref, round_dataset\n",
    "\n",
    "\n",
    "#  Initialize a Doc2Query object with a pre-trained Doc2Query model based on t5-base and trained on MS MARCO(default).\n",
    "#  It generates the queries but we don't append them because we will remove non-relevant queries\n",
    "doc2query = Doc2Query(append=False, num_samples=20)\n",
    "# The generated queries will be scored with the \"crystina-z/monoELECTRA_LCE_nneg3\" pre-trained model \n",
    "# using Electra scorer since it has the best scores in the Doc2Query-- research\n",
    "scorer = ElectraScorer('crystina-z/monoELECTRA_LCE_nneg31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trec_covid_round = 1\n",
    "index_ref_1, round_dataset_1 = doc2query_minus_minus_indexing(trec_covid_round, doc2query, scorer)\n",
    "exp_doc_1 = retrieval(index_ref_1, round_dataset_1)\n",
    "print(exp_doc_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trec_covid_round = 2\n",
    "index_ref_2, round_dataset_2 = doc2query_minus_minus_indexing(trec_covid_round, doc2query, scorer)\n",
    "exp_doc_2 = retrieval(index_ref_2, round_dataset_2)\n",
    "print(exp_doc_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_doc_2 = retrieval(2, index_ref_2, round_dataset_2)\n",
    "print(exp_doc_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trec_covid_round = 3\n",
    "index_ref_3, round_dataset_3 = doc2query_minus_minus_indexing(trec_covid_round, doc2query, scorer)\n",
    "exp_doc_3 = retrieval(index_ref_3, round_dataset_3)\n",
    "print(exp_doc_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trec_covid_round = 4\n",
    "index_ref_4, round_dataset_4 = doc2query_minus_minus_indexing(trec_covid_round, doc2query, scorer)\n",
    "exp_doc_4 = retrieval(index_ref_4, round_dataset_4)\n",
    "print(exp_doc_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trec_covid_round = 5\n",
    "index_ref_5 round_dataset_5 = doc2query_minus_minus_indexing(trec_covid_round, doc2query, scorer)\n",
    "exp_doc_5 = retrieval(index_ref_5, round_dataset_5)\n",
    "print(exp_doc_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_index(trec_covid_round, standard_index_name):\n",
    "    !zip -r {standard_index_name}{trec_covid_round}.zip /kaggle/working/{standard_index_name}{trec_covid_round}\n",
    "trec_covid_round = 2  \n",
    "# Zipping the standard indexes\n",
    "zip_index(trec_covid_round, DOC2QUERY_INDEX_NAME)\n",
    "#Print the link to download the index\n",
    "from IPython.display import FileLink\n",
    "FileLink(f'./{DOC2QUERY_INDEX_NAME}{trec_covid_round}.zip')"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "8d4e39962ee24eea9e5e8b3375a3f990",
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4088624,
     "sourceId": 7094445,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4102661,
     "sourceId": 7124060,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
